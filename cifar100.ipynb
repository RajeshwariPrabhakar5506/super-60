{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53b02a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.24.0-cp313-cp313-win_amd64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\raj\\appdata\\roaming\\python\\python313\\site-packages (from torchvision) (2.3.2)\n",
      "Requirement already satisfied: torch==2.9.0 in c:\\users\\raj\\appdata\\roaming\\python\\python313\\site-packages (from torchvision) (2.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\raj\\appdata\\roaming\\python\\python313\\site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\raj\\appdata\\roaming\\python\\python313\\site-packages (from torch==2.9.0->torchvision) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\raj\\appdata\\roaming\\python\\python313\\site-packages (from torch==2.9.0->torchvision) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\raj\\appdata\\roaming\\python\\python313\\site-packages (from torch==2.9.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\raj\\appdata\\roaming\\python\\python313\\site-packages (from torch==2.9.0->torchvision) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\raj\\appdata\\roaming\\python\\python313\\site-packages (from torch==2.9.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\raj\\appdata\\roaming\\python\\python313\\site-packages (from torch==2.9.0->torchvision) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\raj\\appdata\\roaming\\python\\python313\\site-packages (from torch==2.9.0->torchvision) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\raj\\appdata\\roaming\\python\\python313\\site-packages (from sympy>=1.13.3->torch==2.9.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\raj\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch==2.9.0->torchvision) (3.0.2)\n",
      "Using cached torchvision-0.24.0-cp313-cp313-win_amd64.whl (4.3 MB)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f1c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets  \n",
    "from torchvision import transforms       \n",
    "from torch.utils.data import DataLoader  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84631201",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "train_data=datasets.CIFAR100(root='./data',train=True,download=True,transform=transform)\n",
    "test_data=datasets.CIFAR100(root='./data',train=False,download=True,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308eb23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_data,batch_size=128,shuffle=True)\n",
    "test_loader=DataLoader(test_data,batch_size=128,shuffle=False)# test need not to be shuffled\n",
    "#batch--row doesn't affect the neuron network performance, it just affects the training speed and memory usage.\n",
    "# In general larger batch sizes will use more memory, and smaller batch sizes will train slower.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "084be547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#architecture\n",
    "\n",
    "class CIFAR100MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR100MLP, self).__init__()\n",
    "        #no of layers = 5\n",
    "        #layer_name=nn.linear(i/p neurons,o/p neurons)  \n",
    "        self.flatten = nn.Flatten() #flatten layer it is doing what means is converting 2D image to 1D array\n",
    "        self.fc1 = nn.Linear(32*32*3, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 100)  # 100 classes for CIFAR-100\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "868109fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CIFAR100MLP()\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)#lr=learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7593cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss: 1801.0055270195007\n",
      "epoch_loss: 3602.0123896598816\n",
      "epoch_loss: 5403.018153190613\n",
      "epoch_loss: 7204.017608642578\n",
      "epoch_loss: 9005.023203849792\n",
      "epoch_loss: 10806.02914094925\n",
      "epoch_loss: 12607.03457069397\n",
      "epoch_loss: 14408.041017055511\n",
      "epoch_loss: 16209.046726226807\n",
      "epoch_loss: 18010.052703857422\n"
     ]
    }
   ],
   "source": [
    "epoch_loss=0.0\n",
    "for epoch  in range(10):\n",
    "    for image,label in train_loader:\n",
    "        #send the image to model\n",
    "        output=model(image)\n",
    "        #loss calculation\n",
    "        loss=criterion(output,label)\n",
    "        #backpropagation\n",
    "        loss.backward()\n",
    "        #optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        epoch_loss+=loss.item()\n",
    "    print(f\"epoch_loss: {epoch_loss}\")#loss is scalar value so we use item() to get the value\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62ae4728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total=0\n",
    "correct=0\n",
    "with torch.no_grad():\n",
    "    for image,label in test_loader:\n",
    "        output=model(image)\n",
    "        _,predicted=torch.max(output,1)#.max returns two values max value(neglected) and index of max value\n",
    "        total+=label.size(0)     \n",
    "        correct+=(predicted==label).sum().item() \n",
    "    print('Accuracy: {:.2f}%'.format(100*correct/total))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffa1060",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
